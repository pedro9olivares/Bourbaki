{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNSTgenqN-_f"
      },
      "source": [
        "#Introducción\n",
        "\n",
        "Este notebook entrena a un agente para navegar por un laberinto y llegar al destino deseado. Utiliza el entorno fourRoom-v0 del Gym-MiniGrid como laberinto. El agente se entrena utilizando el algoritmo de gradiente de política básico (REINFORCE) del aprendizaje por refuerzo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I19gFM8lIsP7"
      },
      "outputs": [],
      "source": [
        "!pip install gym\n",
        "!pip install gym-minigrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3y6ZJbLIzA4"
      },
      "outputs": [],
      "source": [
        "import gym, gym_minigrid\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import base64\n",
        "import glob\n",
        "import io\n",
        "import time\n",
        "import copy\n",
        "#import utils\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.categorical import Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uKhObT1JYc0"
      },
      "outputs": [],
      "source": [
        "SEED = 2123"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfizoyMEOWNI"
      },
      "source": [
        "# Definición de componentes de aprendizaje por refuerzo.\n",
        "\n",
        "Se espera que cualquier implementación de refuerzo tenga cuatro componentes:\n",
        "* Un entorno, es decir, donde reside el agente, tiene espacio de acción, es decir, qué acciones son posibles en este entorno y observaciones, es decir, el estado del medio ambiente en un momento dado (posición de las paredes, agente, comida, etc.)\n",
        "* El modelo que actúa como la mente del agente, es decir, toma decisiones sobre qué acciones debe realizar un agente en el entorno.\n",
        "* El rolloutbuffer: la estructura de datos que recopila y almacena datos de entrenamiento.\n",
        "* La política: algoritmos para actualizar los parámetros del modelo para que el modelo tome mejores decisiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "ZlyTr73aL1PH",
        "outputId": "a3e0316d-03f5-4543-d33e-b014602e387f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAANECAYAAAB4mVoFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFy0lEQVR4nO3de5xVdd3o8e9wmQGFAYfbMAoIWGAKaKDzUF5QSC6FkliiGGiGWuAFMo1KEfMJEk1LOdrFIA3L7KWYdtJQUSqRvBzysZIHOKCogKUBgjJcZp0/POynzQzg6AwDv3m/X6/9erGu+7dnzYL5sPbaU5BlWRYAAAAJaVTfAwAAAKhtQgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIH2Cc98cQTUVBQEL/+9a/reyjJmD17dhQUFMTKlStrvO2O4/HEE0/U6phqst8BAwbEgAEDavX5U7Zy5cooKCiI2bNn1/dQAOqF0AH2moKCgvf1qO0fpmm41q1bF+3bt6/VaB43blwUFBTEZz7zmVrZH3vPU089Fddcc02sW7euvocC7AVN6nsAQMNx11135U3feeedMW/evCrzDz/88Pj73/++N4fWIHzhC1+IUaNGRVFRUY23PeGEE+Ldd9+NwsLCWh1TXe13h6uvvjreeeedWtvfs88+G7Nnz45mzZrV2j7rSpcuXeLdd9+Npk2b1vdQ9hlPPfVUTJ06Nc4999xo3bp1fQ8HqGNCB9hrzjnnnLzpp59+OubNm1dlfkQInTrQuHHjaNy48QfatlGjRrX6w/3mzZujsLCw1vf771588cW47bbb4uqrr46rr776Q+8vy7K45JJLYsyYMfHYY4/VwgjrVkFBwfv62m7atCkOPPDAvTAigL3LW9eAfVplZWX853/+ZxxyyCHRrFmzGDhwYCxbtqzKeosWLYohQ4ZEq1at4oADDogTTzwx/vSnP72v53j55Zfj1FNPjQMPPDDat28fEydOjEceeSTvbXRTpkyJpk2bxj/+8Y8q219wwQXRunXr2Lx5c0REHHroofGZz3wmnnjiiejXr180b948evXqldvXfffdF7169YpmzZpF37594//8n//zvsY5YMCAOPLII+OFF16IE088MQ444IA47LDDcm/JevLJJ6O8vDyaN28ePXr0iEcffTRv++ru0dkx1j/+8Y9x7LHHRrNmzaJbt25x55135m27q3tpZs6cGd26dYvmzZvHscceG3/4wx+q3EuzY9tf/vKX8a1vfSsOPvjgOOCAA2LDhg273O+PfvSj6N69e95+a+rSSy+Nz372s3H88cdXWfbuu+9Gz549o2fPnvHuu+/m5r/11lvRsWPH+MQnPhHbt2/P2+auu+6KF198Mf7zP/+zxmP53e9+F8cff3wceOCB0bJly/j0pz8df/3rX/PWOffcc6NFixbx2muvxYgRI6JFixbRrl27uPzyy3Nj2bp1a5SUlMR5551X5Tk2bNgQzZo1i8svvzwiqr9HZ8dzLF++PIYNGxYtW7aM0aNHR8R7wfPVr341OnXqFEVFRdGjR4+44YYbIsuyvOcpKCiICRMmxNy5c+PII4+MoqKiOOKII+Lhhx/OW++aa66JgoKC+O///u8455xzolWrVtGuXbu46qqrIsuyWLVqVZx22mlRXFwcpaWlceONN1Z5TRUVFTFlypQ47LDDoqioKDp16hRXXHFFVFRU1HhM11xzTXzta1+LiIiuXbvm3ir7Qe5ZA/YPQgfYp02fPj3uv//+uPzyy2Py5Mnx9NNP534w2+Hxxx+PE044ITZs2BBTpkyJ73znO7Fu3bo4+eST489//vNu979p06Y4+eST49FHH41LLrkkvvnNb8ZTTz0VV155Zd56X/jCF2Lbtm1xzz335M3fsmVL/PrXv46RI0fm/e/5smXL4uyzz47hw4fHtGnT4l//+lcMHz485syZExMnToxzzjknpk6dGsuXL4/Pf/7zUVlZ+b6+Hv/617/iM5/5TJSXl8f1118fRUVFMWrUqLjnnnti1KhRMWzYsJg+fXps2rQpzjjjjHj77bf3uM9ly5bFGWecEZ/61KfixhtvjIMOOijOPffcKj+I7+y2226LCRMmxCGHHBLXX399HH/88TFixIh49dVXq13/29/+dvz2t7+Nyy+/PL7zne/s8u1qd9xxR1x44YVRWloa119/fXzyk5+MU089NVatWrXnL9D/d++998ZTTz0V119/fbXLmzdvHj/72c9i2bJl8c1vfjM3f/z48bF+/fqYPXt23tWvt99+O6688sr4xje+EaWlpe97HBHvBdKnP/3paNGiRXz3u9+Nq666Kv72t7/FcccdV+WH7O3bt8fgwYOjTZs2ccMNN8SJJ54YN954Y/zoRz+KiIimTZvGZz/72Zg7d25s2bIlb9u5c+dGRUVFjBo1arfj2bZtWwwePDjat28fN9xwQ4wcOTKyLItTTz01brrpphgyZEh873vfix49esTXvva1mDRpUpV9/PGPf4yvfOUrMWrUqLj++utj8+bNMXLkyHjzzTerrHvmmWdGZWVlTJ8+PcrLy+O6666Lm2++OT71qU/FwQcfHN/97nfjsMMOi8svvzwWLFiQ266ysjJOPfXUuOGGG2L48OFxyy23xIgRI+Kmm26KM888s8ZjOv300+Oss86KiIibbrop7rrrrrjrrruiXbt2u/16AfuxDKCejB8/PtvVX0Pz58/PIiI7/PDDs4qKitz873//+1lEZP/1X/+VZVmWVVZWZh/5yEeywYMHZ5WVlbn13nnnnaxr167Zpz71qd2O4cYbb8wiIps7d25u3rvvvpv17Nkzi4hs/vz5ufn9+/fPysvL87a/7777qqzXpUuXLCKyp556KjfvkUceySIia968efbyyy/n5v/whz+ssv2unHjiiVlEZHfffXdu3ksvvZRFRNaoUaPs6aefrvJ8s2bNys2bNWtWFhHZihUrqox1wYIFuXlvvPFGVlRUlH31q1/NzdtxPHaMs6KiImvTpk12zDHHZFu3bs2tN3v27CwishNPPLHKtt26dcveeeedvNe08363bNmStW/fPjvqqKPyjvuPfvSjKvvdlXfeeSfr3LlzNnny5LznuPfee6usO3ny5KxRo0bZggULsnvvvTeLiOzmm2+ust7ll1+ede3aNdu8eXPu6/bpT396j2N5++23s9atW2fjxo3Lm79mzZqsVatWefPHjh2bRUR27bXX5q179NFHZ3379s1N7zi2Dz74YN56w4YNy7p165abXrFiRZXvgR3P8fWvfz1v27lz52YRkV133XV5888444ysoKAgW7ZsWW5eRGSFhYV58/7yl79kEZHdcsstuXlTpkzJIiK74IILcvO2bduWHXLIIVlBQUE2ffr03Px//etfWfPmzbOxY8fm5t11111Zo0aNsj/84Q95Y7r99tuziMj+9Kc/1XhMM2bMqHIOAOlyRQfYp5133nl5//O/421I//f//t+IiFi8eHEsXbo0zj777HjzzTfjn//8Z/zzn/+MTZs2xcCBA2PBggW7vVry8MMPx8EHHxynnnpqbl6zZs1i3LhxVdYdM2ZMLFq0KJYvX56bN2fOnOjUqVOceOKJeet+7GMfi/79++emy8vLIyLi5JNPjs6dO1eZv+P17EmLFi3y/se+R48e0bp16zj88MNz+6rpfj/2sY/lvb2rXbt20aNHj91u++yzz8abb74Z48aNiyZN/ud2z9GjR8dBBx1U7TZjx46N5s2b73Yszz77bLzxxhtx0UUX5R33c889N1q1arXH1xLx3lXArVu3xje+8Y09rnvNNdfEEUccEWPHjo2vfOUrceKJJ8Yll1ySt85///d/x/e///2YMWNGjT/IYd68ebFu3bo466yzct+b//znP6Nx48ZRXl4e8+fPr7LNRRddlDd9/PHH5x2Lk08+Odq2bZt3dfFf//pXzJs3r9orHdX58pe/nDf9v//3/47GjRtXee1f/epXI8uy+N3vfpc3f9CgQdG9e/fcdO/evaO4uLja75kvfelLuT83btw4+vXrF1mWxfnnn5+b37p16yrfc/fee28cfvjh0bNnz7yv3cknnxwRUeVrV5MxAQ2DDyMA9mn/HgURkfsh+l//+ldERCxdujQi3vshelfWr1+/yx++X3755ejevXsUFBTkzT/ssMOqrHvmmWfGZZddFnPmzImrr7461q9fHw899FBMnDixyvY7j3vHD+mdOnWqdv6O1/Puu+/G+vXr89b597dKHXLIIVWeq1WrVnvc7+7sPNaI977Ou9v25ZdfjoiqX6cmTZrEoYceWu02Xbt23eNYduz3Ix/5SN78pk2bRrdu3fa4/cqVK2PGjBkxc+bMaNGixR7XLywsjJ/+9KdxzDHHRLNmzWLWrFlVvr6XXnppfOITn4iRI0fucX872/H9ueOH850VFxfnTTdr1qzKW6l2PhZNmjSJkSNHxt133x0VFRVRVFQU9913X2zduvV9hU6TJk3ikEMOyZv38ssvR1lZWbRs2TJv/uGHH55b/u9q8j1T3bnQrFmzaNu2bZX5//7Wt6VLl8bf//73Xb617I033vjAYwIaBqED7NN29Slh2f+/QXrH1ZoZM2bEUUcdVe267+cH3vfjoIMOis985jO50Pn1r38dFRUV1X5q3K7GvafXc88991S50Tz7t5vBP+h+d+fDbFsTe7qaUxuuvvrqOPjgg2PAgAG5+1/WrFkTERH/+Mc/YuXKldG5c+do1Oh/3tDwyCOPRMR7nwS3dOnSvCB7/PHH4+GHH4777rsv736abdu2xbvvvhsrV66MkpKSKsGyw47vz7vuuqvae3v+/WpYxK6Pxc5GjRoVP/zhD+N3v/tdjBgxIn71q19Fz549o0+fPnvctqioKO/1fxA1+Z6pbt33s31lZWX06tUrvve971W77s5xv7e+j4H9h9AB9ms73qpSXFwcgwYNqvH2Xbp0ib/97W+RZVne/+RX98luEe+9fe20006LZ555JubMmRNHH310HHHEER9s8NUYPHhwzJs3r9b2V1e6dOkSEe99nU466aTc/G3btsXKlSujd+/eH2q/S5cuzbsKsnXr1lixYsUef5B/5ZVXYtmyZdVe/fnKV74SEe9d5drxO1ReeOGFuPbaa+O8886LxYsXx5e+9KX4r//6r9wVsVdeeSUi3ruRfWevvfZadO3aNW666aa47LLLqh3Pju/P9u3bf6Dvz1054YQTomPHjnHPPffEcccdF48//njehyrUVJcuXeLRRx+Nt99+O++qzksvvZRbvrd17949/vKXv8TAgQOrXGX7oGprP8D+wT06wH6tb9++0b1797jhhhti48aNVZZX93HQ/27w4MHx2muvxW9+85vcvM2bN8ePf/zjatcfOnRotG3bNr773e/Gk08+We3VnA+jY8eOMWjQoLzHvqhfv37Rpk2b+PGPfxzbtm3LzZ8zZ86HeqtQv379ol27dnH77bfnfarY7Nmz39dvs7/uuuvi/vvvz3t8+9vfjoiIK664Iu6///7c74zZunVrnHvuuVFWVhbf//73Y/bs2bF27dqYOHFibn8nn3xylf3df//90a5du+jXr1/cf//9MXz48F2OZ/DgwVFcXBzf+c53YuvWrVWW7+n7c1caNWoUZ5xxRjz44INx1113xbZt2973/TnVGTZsWGzfvj1uvfXWvPk33XRTFBQUxNChQz/wvj+oz3/+8/Haa69Vey6+++67sWnTphrvc8exfz/fS8D+zxUdYL/WqFGj+MlPfhJDhw6NI444Is4777w4+OCD47XXXov58+dHcXFxPPjgg7vc/sILL4xbb701zjrrrLj00kujY8eOMWfOnNxHRe/8P8BNmzaNUaNGxa233hqNGzfOfVxtQ1NYWBjXXHNNXHzxxXHyySfH5z//+Vi5cmXMnj272nue3q+mTZvGddddFxdeeGGcfPLJceaZZ8aKFSti1qxZ7+seneOOO67KvB1Xb4455pgYMWJEbv51110XixcvjsceeyxatmwZvXv3jquvvjq+9a1vxRlnnBHDhg2Lzp07V3vvx2WXXRYdOnTI2191iouL47bbbosvfOEL8fGPfzxGjRoV7dq1i1deeSV++9vfxic/+ckqcfF+nXnmmXHLLbfElClTolevXrn7aT6I4cOHx0knnRTf/OY3Y+XKldGnT5/4/e9/Hw888EBcdtlleTf57y1f+MIX4le/+lVcdNFFMX/+/PjkJz8Z27dvj5deeil+9atfxSOPPBL9+vWr0T779u0bERHf/OY3Y9SoUdG0adMYPny4X5gKiRI6wH5vwIABsXDhwvj2t78dt956a2zcuDFKS0ujvLw8Lrzwwt1u26JFi3j88cfj4osvju9///vRokWLGDNmTO7m8+p+s/yYMWPi1ltvjYEDB0bHjh3r6mXt8yZMmBBZlsWNN94Yl19+efTp0yd+85vfxCWXXFLt1+39uuCCC2L79u0xY8aM+NrXvha9evWK3/zmN3HVVVfV2tiff/75+M53vhMTJkzIe+vd17/+9XjggQdi3Lhx8de//jUXSR/G2WefHWVlZTF9+vSYMWNGVFRUxMEHHxzHH398tb/48/36xCc+EZ06dYpVq1Z9qKs5Ee/9h8FvfvObuPrqq+Oee+6JWbNmxaGHHhozZsyIr371qx9q3x9mTHPnzo2bbrop7rzzzrj//vvjgAMOiG7dusWll14aH/3oR2u8z2OOOSa+/e1vx+233x4PP/xwVFZWxooVK4QOJKogc5ceQBU333xzTJw4MV599dU4+OCD85b95S9/iaOOOiruvPPO+MIXvlBPI9w3VVZWRrt27eL000/f5dv/AGBvcI8O0OC9++67edObN2+OH/7wh/GRj3ykSuRERPz4xz+OFi1aVHuDekOyefPmKp9odeedd8Zbb70VAwYMqJ9BAcD/561rQIN3+umnR+fOneOoo46K9evXx89//vN46aWXYs6cOXnrPfjgg/G3v/0tfvSjH8WECRMa/Ntdnn766Zg4cWJ87nOfizZt2sTzzz8fd9xxRxx55JHxuc99rr6HB0AD561rQIN38803x09+8pNYuXJlbN++PT72sY/FFVdcUeW+h0MPPTTWrl0bgwcPjrvuuqvKL1dsaFauXBmXXHJJ/PnPf4633norSkpKYtiwYTF9+vRo3759fQ8PgAZO6AAAAMlxjw4AAJCcegudmTNnxqGHHhrNmjWL8vLy+POf/1xfQwEAABJTL29du+eee2LMmDFx++23R3l5edx8881x7733xpIlS97X+7orKyvj9ddfj5YtW37gX0oHAADsX7Isi7fffjvKysqiUaPdX7Opl9ApLy+PY445JvfboCsrK6NTp05x8cUXx9e//vU9bv/qq69Gp06d6nqYAADAPmjVqlVxyCGH7Hadvf7x0lu2bInnnnsuJk+enJvXqFGjGDRoUCxcuLDabSoqKqKioiI3vaPNpk6d+qF++zYAALD/2Lx5c0yZMuV9ffLpXg+df/7zn7F9+/bo0KFD3vwOHTrESy+9VO0206ZNi6lTp1aZ36xZs2jevHmdjBMAANg3vZ/bV/aLT12bPHlyrF+/PvdYtWpVfQ8JAADYh+31Kzpt27aNxo0bx9q1a/Pmr127NkpLS6vdpqioKIqKivbG8AAAgATs9Ss6hYWF0bdv33jsscdy8yorK+Oxxx6L/v377+3hAAAACdrrV3QiIiZNmhRjx46Nfv36xbHHHhs333xzbNq0Kc4777z6GA4AAJCYegmdM888M/7xj3/E1VdfHWvWrImjjjoqHn744SofUAAAAPBB1EvoRERMmDAhJkyYUF9PDwAAJGy/+NQ1AACAmhA6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJqfXQmTZtWhxzzDHRsmXLaN++fYwYMSKWLFmSt86AAQOioKAg73HRRRfV9lAAAIAGqtZD58knn4zx48fH008/HfPmzYutW7fGKaecEps2bcpbb9y4cbF69erc4/rrr6/toQAAAA1Uk9re4cMPP5w3PXv27Gjfvn0899xzccIJJ+TmH3DAAVFaWlrbTw8AAFD39+isX78+IiJKSkry5s+ZMyfatm0bRx55ZEyePDneeeeduh4KAADQQNT6FZ1/V1lZGZdddll88pOfjCOPPDI3/+yzz44uXbpEWVlZvPDCC3HllVfGkiVL4r777qt2PxUVFVFRUZGb3rBhQ10OGwAA2M/VaeiMHz8+XnzxxfjjH/+YN/+CCy7I/blXr17RsWPHGDhwYCxfvjy6d+9eZT/Tpk2LqVOn1uVQAQCAhNTZW9cmTJgQDz30UMyfPz8OOeSQ3a5bXl4eERHLli2rdvnkyZNj/fr1uceqVatqfbwAAEA6av2KTpZlcfHFF8f9998fTzzxRHTt2nWP2yxevDgiIjp27Fjt8qKioigqKqrNYQIAAAmr9dAZP3583H333fHAAw9Ey5YtY82aNRER0apVq2jevHksX7487r777hg2bFi0adMmXnjhhZg4cWKccMIJ0bt379oeDgAA0ADVeujcdtttEfHeLwX9d7NmzYpzzz03CgsL49FHH42bb745Nm3aFJ06dYqRI0fGt771rdoeCgAA0EDVyVvXdqdTp07x5JNP1vbTAgAA5NT579EBAADY24QOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJKdJfQ8AasPvf//7+h4Ce9kpp5ySN+17oGFx/Bs2x5+dvwegOq7oAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJqfXQueaaa6KgoCDv0bNnz9zyzZs3x/jx46NNmzbRokWLGDlyZKxdu7a2hwEAADRgdXJF54gjjojVq1fnHn/84x9zyyZOnBgPPvhg3HvvvfHkk0/G66+/HqeffnpdDAMAAGigmtTJTps0idLS0irz169fH3fccUfcfffdcfLJJ0dExKxZs+Lwww+Pp59+Ov7jP/6jLoYDAAA0MHVyRWfp0qVRVlYW3bp1i9GjR8crr7wSERHPPfdcbN26NQYNGpRbt2fPntG5c+dYuHBhXQwFAABogGr9ik55eXnMnj07evToEatXr46pU6fG8ccfHy+++GKsWbMmCgsLo3Xr1nnbdOjQIdasWbPLfVZUVERFRUVuesOGDbU9bAAAICG1HjpDhw7N/bl3795RXl4eXbp0iV/96lfRvHnzD7TPadOmxdSpU2triAAAQOLq/OOlW7duHR/96Edj2bJlUVpaGlu2bIl169blrbN27dpq7+nZYfLkybF+/frcY9WqVXU8agAAYH9W56GzcePGWL58eXTs2DH69u0bTZs2jcceeyy3fMmSJfHKK69E//79d7mPoqKiKC4uznsAAADsSq2/de3yyy+P4cOHR5cuXeL111+PKVOmROPGjeOss86KVq1axfnnnx+TJk2KkpKSKC4ujosvvjj69+/vE9cAAIBaU+uh8+qrr8ZZZ50Vb775ZrRr1y6OO+64ePrpp6Ndu3YREXHTTTdFo0aNYuTIkVFRURGDBw+O//W//ldtDwMAAGjAaj10fvnLX+52ebNmzWLmzJkxc+bM2n5qAACAiNgL9+gAAADsbUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5DSp7wFAbTjllFPqewjUM98DDZvj37A5/kB1XNEBAACSI3QAAIDkCB0AACA57tEhCb///e/rewjsZTu/J9/3QMPi+Ddsjj/uy+L9cEUHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5DSp7wEAALvXZg/L39wrowDYv7iiAwAAJEfoAAAAyRE6AABActyjAwD7uBF7WH7H3hgEwH7GFR0AACA5QgcAAEiO0AEAAJLjHh0A2Mcdt4fl7tEBqMoVHQAAIDlCBwAASI7QAQAAkuMeHQDYx5y203TbGq7/QC2OBWB/5YoOAACQHKEDAAAkR+gAAADJcY8OAOxj9vR7c/a0vnt0AFzRAQAAEiR0AACA5AgdAAAgOe7RAYB61mOn6Z413H7n9Xfe35Ia7g8gBa7oAAAAyRE6AABAcoQOAACQHPfoAEA9q+nvzanp/tyjAzRErugAAADJqfXQOfTQQ6OgoKDKY/z48RERMWDAgCrLLrrootoeBgAA0IDV+lvXnnnmmdi+fXtu+sUXX4xPfepT8bnPfS43b9y4cXHttdfmpg844IDaHgYAANCA1XrotGvXLm96+vTp0b179zjxxBNz8w444IAoLS2t7acGgP1Cm52mR9Ty/nfe39ydpt+s5ecD2BfV6T06W7ZsiZ///OfxxS9+MQoKCnLz58yZE23bto0jjzwyJk+eHO+8885u91NRUREbNmzIewAAAOxKnX7q2ty5c2PdunVx7rnn5uadffbZ0aVLlygrK4sXXnghrrzyyliyZEncd999u9zPtGnTYurUqXU5VAAAICF1Gjp33HFHDB06NMrKynLzLrjggtyfe/XqFR07doyBAwfG8uXLo3v37tXuZ/LkyTFp0qTc9IYNG6JTp051N3AAAGC/Vmeh8/LLL8ejjz662ys1ERHl5eUREbFs2bJdhk5RUVEUFRXV+hgBoD7U9u/NqenzPbCXnx+gPtTZPTqzZs2K9u3bx6c//endrrd48eKIiOjYsWNdDQUAAGhg6uSKTmVlZcyaNSvGjh0bTZr8z1MsX7487r777hg2bFi0adMmXnjhhZg4cWKccMIJ0bt377oYCgAA0ADVSeg8+uij8corr8QXv/jFvPmFhYXx6KOPxs033xybNm2KTp06xciRI+Nb3/pWXQwDAABooOokdE455ZTIsqzK/E6dOsWTTz5ZF08JAPuNEfX8fO7RARqCOv09OgAAAPVB6AAAAMkROgAAQHLq9BeGAgARPXaabruXn3/n59t5PEv21kAA9iJXdAAAgOQIHQAAIDlCBwAASI57dACgjo2o7wHsZMRO09+tj0EA1DFXdAAAgOQIHQAAIDlCBwAASI57dACglrXZafq4ehnFru08np/sNP3m3hoIQB1yRQcAAEiO0AEAAJIjdAAAgOS4RwcAatmI+h5ADY3YafqO+hgEQC1zRQcAAEiO0AEAAJIjdAAAgOS4RwcAatm+9ntz9mTn8bpHB0iBKzoAAEByhA4AAJAcoQMAACTHPToA8CF9cqfptvUyig9u5/Hu/Hr+tLcGAlCLXNEBAACSI3QAAIDkCB0AACA57tEBgA9pRH0PoJaN2GnaPTrA/sgVHQAAIDlCBwAASI7QAQAAkuMeHQCooR47Tfesl1HUnZ1fz86vd8neGgjAh+CKDgAAkByhAwAAJEfoAAAAyXGPDgDU0HH1PYC9bOfX6x4dYH/gig4AAJAcoQMAACRH6AAAAMlxjw4A1NCI+h7AXjZip+k76mMQADXkig4AAJAcoQMAACRH6AAAAMlxjw4A7MFp9T2AfczOX48H6mUUALvnig4AAJAcoQMAACRH6AAAAMlxjw4A7MFx9T2AfczOXw/36AD7Ild0AACA5AgdAAAgOUIHAABIjnt0AGAnPXaa7lkvo9h37fz12PnrtWRvDQRgN1zRAQAAkiN0AACA5AgdAAAgOe7RAYCdjKjvAexnRuw0/d36GATATlzRAQAAkiN0AACA5AgdAAAgOe7RAYCd7HyPiXtOAPY/rugAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJCcgizLsvoeRE1t2LAhWrVqFWPGjInCwsL6Hg4AALAXbNmyJe68885Yv359FBcX73ZdV3QAAIDkCB0AACA5QgcAAEhOk/oeANSGn/zkJ/U9BPayL33pS3nTvgcaFse/YXP82fl7AKrjig4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQnBqHzoIFC2L48OFRVlYWBQUFMXfu3LzlWZbF1VdfHR07dozmzZvHoEGDYunSpXnrvPXWWzF69OgoLi6O1q1bx/nnnx8bN278UC8EAABghxqHzqZNm6JPnz4xc+bMapdff/318YMf/CBuv/32WLRoURx44IExePDg2Lx5c26d0aNHx1//+teYN29ePPTQQ7FgwYK44IILPvirAAAA+DdNarrB0KFDY+jQodUuy7Isbr755vjWt74Vp512WkRE3HnnndGhQ4eYO3dujBo1Kv7+97/Hww8/HM8880z069cvIiJuueWWGDZsWNxwww1RVlb2IV4OAABALd+js2LFilizZk0MGjQoN69Vq1ZRXl4eCxcujIiIhQsXRuvWrXORExExaNCgaNSoUSxatKja/VZUVMSGDRvyHgAAALtSq6GzZs2aiIjo0KFD3vwOHTrklq1Zsybat2+ft7xJkyZRUlKSW2dn06ZNi1atWuUenTp1qs1hAwAAidkvPnVt8uTJsX79+txj1apV9T0kAABgH1aroVNaWhoREWvXrs2bv3bt2tyy0tLSeOONN/KWb9u2Ld56663cOjsrKiqK4uLivAcAAMCu1GrodO3aNUpLS+Oxxx7LzduwYUMsWrQo+vfvHxER/fv3j3Xr1sVzzz2XW+fxxx+PysrKKC8vr83hAAAADVSNP3Vt48aNsWzZstz0ihUrYvHixVFSUhKdO3eOyy67LK677rr4yEc+El27do2rrroqysrKYsSIERERcfjhh8eQIUNi3Lhxcfvtt8fWrVtjwoQJMWrUKJ+4BgAA1Ioah86zzz4bJ510Um560qRJERExduzYmD17dlxxxRWxadOmuOCCC2LdunVx3HHHxcMPPxzNmjXLbTNnzpyYMGFCDBw4MBo1ahQjR46MH/zgB7XwcgAAAD5A6AwYMCCyLNvl8oKCgrj22mvj2muv3eU6JSUlcffdd9f0qQEAAN6X/eJT1wAAAGpC6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJKfGobNgwYIYPnx4lJWVRUFBQcydOze3bOvWrXHllVdGr1694sADD4yysrIYM2ZMvP7663n7OPTQQ6OgoCDvMX369A/9YgAAACI+QOhs2rQp+vTpEzNnzqyy7J133onnn38+rrrqqnj++efjvvvuiyVLlsSpp55aZd1rr702Vq9enXtcfPHFH+wVAAAA7KRJTTcYOnRoDB06tNplrVq1innz5uXNu/XWW+PYY4+NV155JTp37pyb37JlyygtLa3p0wMAAOxRnd+js379+igoKIjWrVvnzZ8+fXq0adMmjj766JgxY0Zs27atrocCAAA0EDW+olMTmzdvjiuvvDLOOuusKC4uzs2/5JJL4uMf/3iUlJTEU089FZMnT47Vq1fH9773vWr3U1FRERUVFbnpDRs21OWwAQCA/Vydhc7WrVvj85//fGRZFrfddlveskmTJuX+3Lt37ygsLIwLL7wwpk2bFkVFRVX2NW3atJg6dWpdDRUAAEhMnbx1bUfkvPzyyzFv3ry8qznVKS8vj23btsXKlSurXT558uRYv3597rFq1ao6GDUAAJCKWr+isyNyli5dGvPnz482bdrscZvFixdHo0aNon379tUuLyoqqvZKDwAAQHVqHDobN26MZcuW5aZXrFgRixcvjpKSkujYsWOcccYZ8fzzz8dDDz0U27dvjzVr1kRERElJSRQWFsbChQtj0aJFcdJJJ0XLli1j4cKFMXHixDjnnHPioIMOqr1XBgAANFg1Dp1nn302TjrppNz0jvttxo4dG9dcc0385je/iYiIo446Km+7+fPnx4ABA6KoqCh++ctfxjXXXBMVFRXRtWvXmDhxYt59OwAAAB9GjUNnwIABkWXZLpfvbllExMc//vF4+umna/q0AAAA71ud/x4dAACAvU3oAAAAyRE6AABAcgqyPd1Usw/asGFDtGrVKsaMGROFhYX1PRwAYC/6yY9/Ut9DoJ59adyX6nsI1JMtW7bEnXfeGevXr9/j7+p0RQcAAEiO0AEAAJIjdAAAgOTU+PfowL7oJz/xfu2G5ktfyn9/tu+BhsXxb+B+XN8DAPYHrugAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyalx6CxYsCCGDx8eZWVlUVBQEHPnzs1bfu6550ZBQUHeY8iQIXnrvPXWWzF69OgoLi6O1q1bx/nnnx8bN278UC8EAABghxqHzqZNm6JPnz4xc+bMXa4zZMiQWL16de7xi1/8Im/56NGj469//WvMmzcvHnrooViwYEFccMEFNR89AABANZrUdIOhQ4fG0KFDd7tOUVFRlJaWVrvs73//ezz88MPxzDPPRL9+/SIi4pZbbolhw4bFDTfcEGVlZTUdEgAAQJ46uUfniSeeiPbt20ePHj3iy1/+crz55pu5ZQsXLozWrVvnIiciYtCgQdGoUaNYtGhRXQwHAABoYGp8RWdPhgwZEqeffnp07do1li9fHt/4xjdi6NChsXDhwmjcuHGsWbMm2rdvnz+IJk2ipKQk1qxZU+0+KyoqoqKiIje9YcOG2h42AACQkFoPnVGjRuX+3KtXr+jdu3d07949nnjiiRg4cOAH2ue0adNi6tSptTVEAAAgcXX+8dLdunWLtm3bxrJlyyIiorS0NN544428dbZt2xZvvfXWLu/rmTx5cqxfvz73WLVqVV0PGwAA2I/Veei8+uqr8eabb0bHjh0jIqJ///6xbt26eO6553LrPP7441FZWRnl5eXV7qOoqCiKi4vzHgAAALtS47eubdy4MXd1JiJixYoVsXjx4igpKYmSkpKYOnVqjBw5MkpLS2P58uVxxRVXxGGHHRaDBw+OiIjDDz88hgwZEuPGjYvbb789tm7dGhMmTIhRo0b5xDUAAKBW1PiKzrPPPhtHH310HH300RERMWnSpDj66KPj6quvjsaNG8cLL7wQp556anz0ox+N888/P/r27Rt/+MMfoqioKLePOXPmRM+ePWPgwIExbNiwOO644+JHP/pR7b0qAACgQavxFZ0BAwZElmW7XP7II4/scR8lJSVx99131/SpAQAA3pc6v0cHAABgbxM6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACSnIMuyrL4HUVMbNmyIVq1axZgxY6KwsLC+hwMAAOwFW7ZsiTvvvDPWr18fxcXFu13XFR0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOTUOnQULFsTw4cOjrKwsCgoKYu7cuXnLCwoKqn3MmDEjt86hhx5aZfn06dM/9IsBAACI+AChs2nTpujTp0/MnDmz2uWrV6/Oe/z0pz+NgoKCGDlyZN561157bd56F1988Qd7BQAAADtpUtMNhg4dGkOHDt3l8tLS0rzpBx54IE466aTo1q1b3vyWLVtWWRcAAKA21Ok9OmvXro3f/va3cf7551dZNn369GjTpk0cffTRMWPGjNi2bdsu91NRUREbNmzIewAAAOxKja/o1MTPfvazaNmyZZx++ul58y+55JL4+Mc/HiUlJfHUU0/F5MmTY/Xq1fG9732v2v1MmzYtpk6dWpdDBQAAElKnofPTn/40Ro8eHc2aNcubP2nSpNyfe/fuHYWFhXHhhRfGtGnToqioqMp+Jk+enLfNhg0bolOnTnU3cAAAYL9WZ6Hzhz/8IZYsWRL33HPPHtctLy+Pbdu2xcqVK6NHjx5VlhcVFVUbQAAAANWps3t07rjjjujbt2/06dNnj+suXrw4GjVqFO3bt6+r4QAAAA1Ija/obNy4MZYtW5abXrFiRSxevDhKSkqic+fOEfHeW8vuvffeuPHGG6tsv3Dhwli0aFGcdNJJ0bJly1i4cGFMnDgxzjnnnDjooIM+xEsBAAB4T41D59lnn42TTjopN73j3pmxY8fG7NmzIyLil7/8ZWRZFmeddVaV7YuKiuKXv/xlXHPNNVFRURFdu3aNiRMn5t2DAwAA8GEUZFmW1fcgamrDhg3RqlWrGDNmTBQWFtb3cAAAgL1gy5Ytceedd8b69eujuLh4t+vW6e/RAQAAqA9CBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEhOk/oewAeRZVlERGzZsqWeRwIAAOwtO37+39EDu1OQvZ+19jGvvvpqdOrUqb6HAQAA1INVq1bFIYccstt19svQqaysjNdffz2yLIvOnTvHqlWrori4uL6H1eBt2LAhOnXq5HjsQxyTfYvjsW9xPPYtjse+xzHZtzge78myLN5+++0oKyuLRo12fxfOfvnWtUaNGsUhhxwSGzZsiIiI4uLiBn3A9zWOx77HMdm3OB77Fsdj3+J47Hsck32L4xHRqlWr97WeDyMAAACSI3QAAIDk7NehU1RUFFOmTImioqL6HgrheOyLHJN9i+Oxb3E89i2Ox77HMdm3OB41t19+GAEAAMDu7NdXdAAAAKojdAAAgOQIHQAAIDlCBwAASM5+HTozZ86MQw89NJo1axbl5eXx5z//ub6H1CBMmzYtjjnmmGjZsmW0b98+RowYEUuWLMlbZ8CAAVFQUJD3uOiii+ppxGm75pprqnyte/bsmVu+efPmGD9+fLRp0yZatGgRI0eOjLVr19bjiNN26KGHVjkeBQUFMX78+IhwbuwNCxYsiOHDh0dZWVkUFBTE3Llz85ZnWRZXX311dOzYMZo3bx6DBg2KpUuX5q3z1ltvxejRo6O4uDhat24d559/fmzcuHEvvop07O54bN26Na688sro1atXHHjggVFWVhZjxoyJ119/PW8f1Z1X06dP38uvJA17Oj/OPffcKl/rIUOG5K3j/Kg9ezoe1f17UlBQEDNmzMit4/zYtf02dO65556YNGlSTJkyJZ5//vno06dPDB48ON544436HlrynnzyyRg/fnw8/fTTMW/evNi6dWuccsopsWnTprz1xo0bF6tXr849rr/++noacfqOOOKIvK/1H//4x9yyiRMnxoMPPhj33ntvPPnkk/H666/H6aefXo+jTdszzzyTdyzmzZsXERGf+9zncus4N+rWpk2bok+fPjFz5sxql19//fXxgx/8IG6//fZYtGhRHHjggTF48ODYvHlzbp3Ro0fHX//615g3b1489NBDsWDBgrjgggv21ktIyu6OxzvvvBPPP/98XHXVVfH888/HfffdF0uWLIlTTz21yrrXXntt3nlz8cUX743hJ2dP50dExJAhQ/K+1r/4xS/yljs/as+ejse/H4fVq1fHT3/60ygoKIiRI0fmref82IVsP3Xsscdm48ePz01v3749Kysry6ZNm1aPo2qY3njjjSwisieffDI378QTT8wuvfTS+htUAzJlypSsT58+1S5bt25d1rRp0+zee+/Nzfv73/+eRUS2cOHCvTTChu3SSy/NunfvnlVWVmZZ5tzY2yIiu//++3PTlZWVWWlpaTZjxozcvHXr1mVFRUXZL37xiyzLsuxvf/tbFhHZM888k1vnd7/7XVZQUJC99tpre23sKdr5eFTnz3/+cxYR2csvv5yb16VLl+ymm26q28E1QNUdj7Fjx2annXbaLrdxftSd93N+nHbaadnJJ5+cN8/5sWv75RWdLVu2xHPPPReDBg3KzWvUqFEMGjQoFi5cWI8ja5jWr18fERElJSV58+fMmRNt27aNI488MiZPnhzvvPNOfQyvQVi6dGmUlZVFt27dYvTo0fHKK69ERMRzzz0XW7duzTtXevbsGZ07d3au7AVbtmyJn//85/HFL34xCgoKcvOdG/VnxYoVsWbNmrxzolWrVlFeXp47JxYuXBitW7eOfv365dYZNGhQNGrUKBYtWrTXx9zQrF+/PgoKCqJ169Z586dPnx5t2rSJo48+OmbMmBHbtm2rnwE2AE888US0b98+evToEV/+8pfjzTffzC1zftSftWvXxm9/+9s4//zzqyxzflSvSX0P4IP45z//Gdu3b48OHTrkze/QoUO89NJL9TSqhqmysjIuu+yy+OQnPxlHHnlkbv7ZZ58dXbp0ibKysnjhhRfiyiuvjCVLlsR9991Xj6NNU3l5ecyePTt69OgRq1evjqlTp8bxxx8fL774YqxZsyYKCwur/MDQoUOHWLNmTf0MuAGZO3durFu3Ls4999zcPOdG/drxfV/dvx87lq1Zsybat2+ft7xJkyZRUlLivKljmzdvjiuvvDLOOuusKC4uzs2/5JJL4uMf/3iUlJTEU089FZMnT47Vq1fH9773vXocbZqGDBkSp59+enTt2jWWL18e3/jGN2Lo0KGxcOHCaNy4sfOjHv3sZz+Lli1bVnn7ufNj1/bL0GHfMX78+HjxxRfz7gmJiLz36vbq1Ss6duwYAwcOjOXLl0f37t339jCTNnTo0Nyfe/fuHeXl5dGlS5f41a9+Fc2bN6/HkXHHHXfE0KFDo6ysLDfPuQHV27p1a3z+85+PLMvitttuy1s2adKk3J979+4dhYWFceGFF8a0adOiqKhobw81aaNGjcr9uVevXtG7d+/o3r17PPHEEzFw4MB6HBk//elPY/To0dGsWbO8+c6PXdsv37rWtm3baNy4cZVPjlq7dm2UlpbW06gangkTJsRDDz0U8+fPj0MOOWS365aXl0dExLJly/bG0Bq01q1bx0c/+tFYtmxZlJaWxpYtW2LdunV56zhX6t7LL78cjz76aHzpS1/a7XrOjb1rx/f97v79KC0trfLBNtu2bYu33nrLeVNHdkTOyy+/HPPmzcu7mlOd8vLy2LZtW6xcuXLvDLAB69atW7Rt2zb3d5Tzo3784Q9/iCVLluzx35QI58e/2y9Dp7CwMPr27RuPPfZYbl5lZWU89thj0b9//3ocWcOQZVlMmDAh7r///nj88ceja9eue9xm8eLFERHRsWPHOh4dGzdujOXLl0fHjh2jb9++0bRp07xzZcmSJfHKK684V+rYrFmzon379vHpT396t+s5N/aurl27Rmlpad45sWHDhli0aFHunOjfv3+sW7cunnvuudw6jz/+eFRWVubClNqzI3KWLl0ajz76aLRp02aP2yxevDgaNWpU5S1U1L5XX3013nzzzdzfUc6P+nHHHXdE3759o0+fPntc1/nxP/bbt65NmjQpxo4dG/369Ytjjz02br755ti0aVOcd9559T205I0fPz7uvvvueOCBB6Jly5a59+S2atUqmjdvHsuXL4+77747hg0bFm3atIkXXnghJk6cGCeccEL07t27nkefnssvvzyGDx8eXbp0iddffz2mTJkSjRs3jrPOOitatWoV559/fkyaNClKSkqiuLg4Lr744ujfv3/8x3/8R30PPVmVlZUxa9asGDt2bDRp8j9/zTo39o6NGzfmXSFbsWJFLF68OEpKSqJz585x2WWXxXXXXRcf+chHomvXrnHVVVdFWVlZjBgxIiIiDj/88BgyZEiMGzcubr/99ti6dWtMmDAhRo0alfc2RN6f3R2Pjh07xhlnnBHPP/98PPTQQ7F9+/bcvyklJSVRWFgYCxcujEWLFsVJJ50ULVu2jIULF8bEiRPjnHPOiYMOOqi+XtZ+a3fHo6SkJKZOnRojR46M0tLSWL58eVxxxRVx2GGHxeDBgyPC+VHb9vT3VcR7/xlz7733xo033lhle+fHHtT3x759GLfcckvWuXPnrLCwMDv22GOzp59+ur6H1CBERLWPWbNmZVmWZa+88kp2wgknZCUlJVlRUVF22GGHZV/72tey9evX1+/AE3XmmWdmHTt2zAoLC7ODDz44O/PMM7Nly5bllr/77rvZV77yleyggw7KDjjggOyzn/1stnr16noccfoeeeSRLCKyJUuW5M13buwd8+fPr/bvqLFjx2ZZ9t5HTF911VVZhw4dsqKiomzgwIFVjtWbb76ZnXXWWVmLFi2y4uLi7Lzzzsvefvvteng1+7/dHY8VK1bs8t+U+fPnZ1mWZc8991xWXl6etWrVKmvWrFl2+OGHZ9/5zneyzZs31+8L20/t7ni888472SmnnJK1a9cua9q0adalS5ds3Lhx2Zo1a/L24fyoPXv6+yrLsuyHP/xh1rx582zdunVVtnd+7F5BlmVZndcUAADAXrRf3qMDAACwO0IHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5Pw/lK5Wu5ChCBsAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def display_environment() -> None:\n",
        "    '''\n",
        "    Converts an environment to an image and displays it on the notebook.\n",
        "    '''\n",
        "    # Set the render mode when creating the environment\n",
        "    env = gym.make('MiniGrid-Empty-Random-6x6-v0', render_mode=\"rgb_array\")\n",
        "    env.reset()\n",
        "    # Call render without any arguments\n",
        "    img = env.render()\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(img,cmap='gray')\n",
        "    plt.title(\"The gym-minigrid 4x4 environment\")\n",
        "    plt.show()\n",
        "\n",
        "# Call the function without any arguments\n",
        "display_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItPYKZVXOnY-"
      },
      "source": [
        "No es eficiente trabajar con un entorno 3D, por lo que aplanamos el entorno a un vector 1D. Para hacer esto utilizamos el FlatObsWrapper definido a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TQxhmbPMZoQ"
      },
      "outputs": [],
      "source": [
        "class FlatObsWrapper(gym.core.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "\n",
        "        # Since the outer walls are always present, we remove left, right, top, bottom walls\n",
        "        # from the observation space of the agent. There are 3 channels, but for simplicity\n",
        "        # in this assignment, we will deal with flattened version of state.\n",
        "\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            shape=((self.env.width-2) * (self.env.height-2) * 3,),  # number of cells\n",
        "            #dtype='uint8'\n",
        "            dtype = float\n",
        "        )\n",
        "        self.unwrapped.max_steps = 100\n",
        "\n",
        "    def observation(self, obs):\n",
        "        '''\n",
        "        This method is called in the reset() and step() functions to get the observation.\n",
        "        env.reset() returns the environment with the goal, walls and empty spaces in place but no agent in it.\n",
        "        This function places the agent into the environment and flattens the env.\n",
        "        '''\n",
        "        env = self.unwrapped\n",
        "        full_grid = env.grid.encode()\n",
        "\n",
        "        #places the agent in the grid\n",
        "        full_grid[env.agent_pos[0]][env.agent_pos[1]] = np.array([\n",
        "            gym_minigrid.minigrid.OBJECT_TO_IDX['agent'],\n",
        "            gym_minigrid.minigrid.COLOR_TO_IDX['red'],\n",
        "            env.agent_dir\n",
        "        ])\n",
        "\n",
        "        #remove outer walls of the environment (for efficiency)\n",
        "        full_grid = full_grid[1:-1, 1:-1]\n",
        "\n",
        "        flattened_grid = full_grid.ravel()\n",
        "        return flattened_grid\n",
        "\n",
        "    def render(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        This removes the default visualization of the partially observable field of view.\n",
        "        \"\"\"\n",
        "        kwargs['highlight'] = False\n",
        "        return self.unwrapped.render(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kyipOHnMdWJ"
      },
      "outputs": [],
      "source": [
        "env = FlatObsWrapper(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANgyz6CoOvE4"
      },
      "source": [
        "**Rollout buffer:** El aprendizaje reforzado funciona recopilando primero datos que luego serán utilizados por el usuario para capacitar al agente. El búfer de implementación es la estructura de datos para almacenar dichos datos. Una instancia en los datos recopilados consiste en una observación, una acción realizada, la recompensa obtenida\n",
        "y si la acción resultó en un estado terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgaBKWF9MfjZ"
      },
      "outputs": [],
      "source": [
        "class RolloutBuffer():\n",
        "    def __init__(self, rollout_size, obs_size):\n",
        "        '''\n",
        "        Initializes the size i.e. number of instances and of the rolloutbuffer\n",
        "        '''\n",
        "        self.rollout_size = rollout_size\n",
        "        self.obs_size = obs_size\n",
        "        self.reset()\n",
        "\n",
        "    def insert(self, step, done, action, log_prob, reward, obs):\n",
        "        '''\n",
        "        Inserts an instance i.e. a data example to the rolloutbuffer.\n",
        "        '''\n",
        "        self.done[step].copy_(done)\n",
        "        self.actions[step].copy_(action)\n",
        "        self.log_probs[step].copy_(log_prob)\n",
        "        self.rewards[step].copy_(reward)\n",
        "        self.obs[step].copy_(obs)\n",
        "\n",
        "    def reset(self):\n",
        "        '''\n",
        "        Clears the rollout buffer of any existing data.\n",
        "        '''\n",
        "        self.done = torch.zeros(self.rollout_size, 1)\n",
        "        self.returns = torch.zeros(self.rollout_size + 1, 1, requires_grad=False)\n",
        "        # Assuming Discrete Action Space\n",
        "        self.actions = torch.zeros(self.rollout_size, 1, dtype=torch.int64)\n",
        "        self.log_probs = torch.zeros(self.rollout_size, 1)\n",
        "        self.rewards = torch.zeros(self.rollout_size, 1)\n",
        "        self.obs = torch.zeros(self.rollout_size, self.obs_size)\n",
        "\n",
        "    def compute_returns(self, gamma):\n",
        "        '''\n",
        "        Computes the expected return of each instance.\n",
        "        Expected return computation for an instance uses a group of intances before the terminal state is used.\n",
        "        '''\n",
        "        self.last_done = (self.done == 1).nonzero().max()\n",
        "        self.returns[self.last_done + 1] = 0.\n",
        "\n",
        "        # Accumulate discounted returns\n",
        "        for step in reversed(range(self.last_done + 1)):\n",
        "            self.returns[step] = self.returns[step + 1] * \\\n",
        "                gamma * (1 - self.done[step]) + self.rewards[step]\n",
        "\n",
        "\n",
        "    def batch_sampler(self, batch_size, get_old_log_probs=False):\n",
        "        '''\n",
        "        Returns a small random amount of instances from the rolloutbuffer.\n",
        "        '''\n",
        "        sampler = BatchSampler(SubsetRandomSampler(range(self.last_done)), batch_size, drop_last=True)\n",
        "\n",
        "        for indices in sampler:\n",
        "            if get_old_log_probs:\n",
        "                yield self.actions[indices], self.returns[indices], self.obs[indices], self.log_probs[indices]\n",
        "            else:\n",
        "                yield self.actions[indices], self.returns[indices], self.obs[indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22X6CLA8O5bZ"
      },
      "source": [
        "**El actor/agente/modelo:** Es la red neuronal que ordena qué acción debe realizar un agente dado el estado actual del entorno.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXIk_dlzMhdr"
      },
      "outputs": [],
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(num_inputs, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, num_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.fc(state)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUBrRhFhPBia"
      },
      "source": [
        "**La Política:** Equivale a un optimizador en el aprendizaje supervisado regular a través de redes neuronales. Le preocupa cómo actualizar los parámetros del modelo para que el modelo pueda hacer mejores recomendaciones de acción.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc5DtL5NMjm9"
      },
      "outputs": [],
      "source": [
        "class Policy():\n",
        "    def __init__(self, num_inputs, num_actions, hidden_dim, learning_rate, batch_size, policy_epochs, entropy_coef):\n",
        "        self.actor = ActorNetwork(num_inputs, num_actions, hidden_dim)\n",
        "        self.optimizer = optim.Adam(self.actor.parameters(), lr=learning_rate)\n",
        "        self.batch_size = batch_size\n",
        "        self.policy_epochs = policy_epochs\n",
        "        self.entropy_coef = entropy_coef\n",
        "\n",
        "    def act(self, state):\n",
        "        logits = self.actor(state)\n",
        "        dist = Categorical(logits=logits)\n",
        "        action = dist.sample()\n",
        "        log_prob = dist.log_prob(action)\n",
        "        return action, log_prob\n",
        "\n",
        "    def evaluate_actions(self, state, action):\n",
        "        logits = self.actor(state)\n",
        "        dist = Categorical(logits=logits)\n",
        "        log_prob = dist.log_prob(action.squeeze(-1)).view(-1, 1)\n",
        "        entropy = dist.entropy().view(-1, 1)\n",
        "        return log_prob, entropy\n",
        "\n",
        "    def update(self, rollouts):\n",
        "        for epoch in range(self.policy_epochs):\n",
        "            data = rollouts.batch_sampler(self.batch_size)\n",
        "\n",
        "            for sample in data:\n",
        "                actions_batch, returns_batch, obs_batch = sample\n",
        "\n",
        "                log_probs_batch, entropy_batch = self.evaluate_actions(obs_batch, actions_batch)\n",
        "\n",
        "                policy_loss = -(log_probs_batch * returns_batch).mean()\n",
        "                entropy_loss = -entropy_batch.mean()\n",
        "\n",
        "                loss = policy_loss + self.entropy_coef * entropy_loss\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward(retain_graph=False)\n",
        "                self.optimizer.step()\n",
        "\n",
        "    @property\n",
        "    def num_params(self):\n",
        "        return sum(p.numel() for p in self.actor.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2A-ka4-MmOt"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 32         # dimension of the hidden state in actor network\n",
        "learning_rate = 1e-3     # learning rate of policy update\n",
        "batch_size = 1024        # batch size for policy update\n",
        "policy_epochs = 4        # number of epochs per policy update\n",
        "entropy_coef = 0.001     # hyperparameter to vary the contribution of entropy loss\n",
        "\n",
        "rollout_size = 2050      # number of collected rollout steps per policy update\n",
        "num_updates = 50         # number of training policy iterations\n",
        "discount = 0.99          # discount factor\n",
        "plotting_iters = 10      # interval for logging graphs and policy rollouts\n",
        "\n",
        "\n",
        "obs_size = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "rollouts = RolloutBuffer(rollout_size, obs_size)\n",
        "policy = Policy(obs_size, num_actions,  hidden_dim, learning_rate, batch_size, policy_epochs, entropy_coef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWGTDIE8Plq0"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUSzhix-Mopb"
      },
      "outputs": [],
      "source": [
        "def train(env, rollouts, policy, num_updates, discount, plotting_iters):\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "\n",
        "    rollout_time, update_time = utils.AverageMeter(), utils.AverageMeter()  # Loggers\n",
        "    rewards, success_rate = [], []\n",
        "\n",
        "    print(\"Training model with {} parameters...\".format(policy.num_params))\n",
        "\n",
        "    # Training Loop\n",
        "    for j in range(num_updates):\n",
        "        ## Initialization\n",
        "        avg_eps_reward, avg_success_rate = utils.AverageMeter(), utils.AverageMeter()\n",
        "        done = False\n",
        "\n",
        "        env.seed(SEED)\n",
        "        prev_obs = env.reset()\n",
        "        prev_obs = torch.tensor(prev_obs, dtype=torch.float32)\n",
        "        eps_reward = 0.\n",
        "        start_time = time.time()\n",
        "\n",
        "        ## Collect rollouts\n",
        "        for step in range(rollouts.rollout_size):\n",
        "            if done:\n",
        "                # Store episode statistics\n",
        "                avg_eps_reward.update(eps_reward)\n",
        "                if 'success' in info:\n",
        "                    avg_success_rate.update(int(info['success']))\n",
        "\n",
        "                # Reset Environment\n",
        "                obs = env.reset()\n",
        "                obs = torch.tensor(obs, dtype=torch.float32)\n",
        "                eps_reward = 0.\n",
        "            else:\n",
        "                obs = prev_obs\n",
        "\n",
        "            action, log_prob = policy.act(obs)\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            rollouts.insert(step, torch.tensor(done, dtype=torch.float32), action, log_prob, torch.tensor(reward, dtype=torch.float32), prev_obs)\n",
        "\n",
        "            prev_obs = torch.tensor(obs, dtype=torch.float32)\n",
        "            eps_reward += reward\n",
        "\n",
        "        # Use the rollout buffer's function to compute the returns for all stored rollout steps.\n",
        "        rollouts.compute_returns(discount)\n",
        "\n",
        "        rollout_done_time = time.time()\n",
        "\n",
        "\n",
        "        # Call the policy's update function using the collected rollouts\n",
        "        policy.update(rollouts)\n",
        "\n",
        "        update_done_time = time.time()\n",
        "        rollouts.reset()\n",
        "\n",
        "        ## log metrics\n",
        "        rewards.append(avg_eps_reward.avg)\n",
        "\n",
        "        if avg_success_rate.count > 0: success_rate.append(avg_success_rate.avg)\n",
        "\n",
        "        rollout_time.update(rollout_done_time - start_time)\n",
        "        update_time.update(update_done_time - rollout_done_time)\n",
        "        print('it {}: avgR: {:.3f} -- rollout_time: {:.3f}sec -- update_time: {:.3f}sec'.format(j, avg_eps_reward.avg, rollout_time.avg, update_time.avg))\n",
        "\n",
        "        if j % plotting_iters == 0 and j != 0:\n",
        "           utils.plot_learning_curve(rewards, success_rate, num_updates)\n",
        "           #log_policy_rollout(policy, params.env_name, pytorch_policy=True)\n",
        "\n",
        "    clear_output()   # this removes all training outputs to keep the notebook clean, DON'T REMOVE THIS LINE!\n",
        "    return rewards, success_rate #average rewards in each rollout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "CN3_BJfbMqfW",
        "outputId": "54ca3d09-d6f2-430f-9d96-119ff2559a7b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'utils' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5bb42a23334b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavg_rollout_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-d8a0331dd40e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, rollouts, policy, num_updates, discount, plotting_iters)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrollout_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Loggers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
          ]
        }
      ],
      "source": [
        "avg_rollout_rewards, success_rate = train(env, rollouts, policy, num_updates, discount, plotting_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDWDjHqDPPbn"
      },
      "source": [
        "**Evaluación:** Reproduzca un solo episodio en un entorno siguiendo la política dada e informe los resultados.  gym.wrappers.Monitor envuelve un entorno de modo que registra todas las acciones que tienen lugar en el entorno antes de que se alcance un estado terminal. Una vez que se alcanza el estado terminal, la grabación se almacena. Si se inicia un nuevo eposido, el archivo grabado se sobrescribe"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
