{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22aa8a11",
   "metadata": {},
   "source": [
    "# Un primer modelo generativo de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10196069",
   "metadata": {},
   "source": [
    "En este notebook, usaremos los conceptos de probabilidad (condicional) y n-gramas para generar texto (similar a como lo hace ChatGPT o Gemini)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7ec1b",
   "metadata": {},
   "source": [
    "## Carga de un libro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd1187",
   "metadata": {},
   "source": [
    "## Histogramas de palabras y letras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd1836",
   "metadata": {},
   "source": [
    "## Generación vía letras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fedcfc",
   "metadata": {},
   "source": [
    "## Generación vía palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0cffe1",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un vocabulario con $k$ palabras distintas y $n$ es la longitud de nuestro texto.  \n",
    "\n",
    "Si modelamos que cada palabra en el texto es elegida de forma independiente según una distribución de probabilidades $(p_1, p_2, \\dots, p_k)$ sobre el vocabulario, entonces el vector de conteos $(X_1, X_2, \\dots, X_k)$, donde $X_i$ es el número de veces que aparece la palabra $i$, sigue una distribución multinomial:  \n",
    "\n",
    "$$(X_1, X_2, \\dots, X_k) \\sim \\text{Multinomial}(n, (p_1, p_2, \\dots, p_k))$$  \n",
    "\n",
    "Este modelo es una base común en procesamiento de lenguaje natural, aunque en la práctica las palabras no son independientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = [\n",
    "    'el', 'la', 'de', 'en', 'un',     # palabras funcionales\n",
    "    'gato', 'niña', 'perro', 'casa', 'alfombra',  # sustantivos\n",
    "    'duerme', 'juega', 'come'  # verbos\n",
    "]\n",
    "\n",
    "probabilidades = [\n",
    "    0.12, 0.10, 0.10, 0.06, 0.06,  # funcionales: 0.44\n",
    "    0.10, 0.08, 0.08, 0.08, 0.06,  # sustantivos: 0.40\n",
    "    0.06, 0.05, 0.05  # verbos: 0.15\n",
    "]\n",
    "\n",
    "# Número de palabras en el fragmento de texto\n",
    "n_palabras = 30\n",
    "\n",
    "# Simulamos el fragmento de texto como una secuencia de palabras\n",
    "fragmento = np.random.choice(vocabulario, size=n_palabras, p=probabilidades)\n",
    "\n",
    "# Contamos la frecuencia de cada palabra\n",
    "unique, counts = np.unique(fragmento, return_counts=True)\n",
    "\n",
    "# Visualización\n",
    "plt.bar(unique, counts, color='skyblue')\n",
    "plt.title(f'Conteo multinomial de palabras en un fragmento de {n_palabras} palabras')\n",
    "plt.xlabel('Palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "print(\"Fragmento generado:\")\n",
    "print(' '.join(fragmento))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
